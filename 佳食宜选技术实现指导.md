# 餐饮下单系统技术实现指导建议与补充

## 一、整体技术架构适配与分层设计

基于“SpringBoot+MyBatis-Plus+MySQL+Redis+Netty”技术栈，结合餐饮下单“高频交互、实时协同”的业务特性，建议采用“分层架构+微服务雏形”的设计思路，为后续业务扩容预留扩展空间，核心架构设计如下：

- **后端分层**：采用“Controller→Service→DAO→数据模型”经典分层，各层职责边界清晰——Controller（接口层，负责请求接收与响应封装）；Service（业务逻辑层，细分BizService处理复杂业务、BaseService封装通用逻辑）；DAO（数据访问层，基于MyBatis-Plus实现CRUD）；数据模型区分Entity（数据库映射）、DTO（前后端传输）、VO（前端展示），杜绝数据模型混用导致的逻辑混乱；

- **中间件协同**：明确各中间件核心职责——Redis承载热点数据缓存、分布式锁、轻量消息队列；Netty专注长连接实时消息推送；MySQL存储核心业务数据，借助MyBatis-Plus代码生成器快速生成基础数据操作接口，提升开发效率；

- **前端协同**：桌面端（Electron+Vue3）与小程序端（UniApp）具备完全一致的功能属性，覆盖用户点单、支付、订单追踪及商家订单管理、菜单配置等全场景操作；核心差异体现在设备适配优化——桌面端侧重大屏多任务操作体验，小程序端聚焦移动端轻量化交互，双端通过统一后端API接口实现数据实时同步。

## 二、核心业务模块技术落地建议

### 2.1 个性化推荐模块：数据缓存与计算优化

该模块依赖用户行为数据（历史点单记录、推荐拒绝行为）与实时数据（定位、天气），技术实现需在“推荐精准度”与“接口响应速度”间寻求最优平衡，核心方案如下：

- **用户行为数据存储策略**：**偏好标签缓存**：高频访问的“用户偏好标签”（如“忌辣”“偏好甜口”）采用Redis Hash结构存储，缓存Key设计为“user:prefer:{userId}”，Field为标签类型，Value为权重值（例：累计3次拒绝甜口菜品，权重设为0.1），缓存有效时长7天，更新时采用“先更MySQL再删Redis”的策略确保数据一致；

- **历史订单复用**：历史订单数据（支撑复购推荐）持久化至MySQL，通过MyBatis-Plus条件构造器快速筛选“近30天高频点单菜品”，同时利用Redis ZSet存储“用户菜品热度榜”，Score为点单次数，实现热点菜品快速查询。

- **实时数据对接与推荐逻辑**：**第三方接口封装**：后端统一封装定位、天气服务客户端（如LocationClient、WeatherClient），通过Spring Boot Starter方式集成，配置严格超时阈值（定位≤1秒，天气≤2秒），接口调用失败时降级使用本地缓存的上一次有效数据，保障推荐服务可用性；

- **推荐引擎实现**：在Service层构建轻量推荐引擎，优先从Redis获取用户偏好与实时数据，按“天气适配度×偏好权重×菜品热度”计算推荐优先级，结果缓存至“user:recommend:{userId}”，缓存时长1小时，避免重复计算消耗资源。

**实时数据对接**：
        定位与天气API调用：后端封装统一的“第三方服务客户端”（如WeatherClient、LocationClient），通过Spring Boot Starter方式集成，设置超时时间（定位≤1s，天气≤2s），失败时降级使用本地缓存的上一次数据；

推荐逻辑实现：在Service层编写推荐引擎，优先从Redis获取用户偏好+实时数据，计算推荐权重，结果缓存至Redis“user:recommend:{userId}”，缓存时间1小时，避免重复计算。

### 2.2 订单全链路管理：分布式事务与状态同步

订单模块覆盖“创建-支付-履约-完成”全流程，核心痛点为“状态一致性”“并发修改冲突”“进度实时同步”，技术落地需围绕这三大痛点设计解决方案：

消息可靠性保障：推送前将消息存入Redis“order:msg:{orderId}”，前端接收后返回ACK，Netty服务未收到ACK则10s内重试2次，仍失败则标记为“待推送”，通过定时任务补偿推送。

- **订单状态规范化设计**：**状态定义**：数据库订单表（t_order）设计“status”字段，采用枚举类统一管理状态（0-待支付、1-待接单、2-备菜中、3-烹饪中、4-待上菜、5-已完成、6-已取消），明确各状态的业务含义与流转规则；

- **状态管控**：状态变更通过Service层统一方法实现，嵌入操作日志记录（操作人ID、操作时间、原状态、新状态），确保状态变更可追溯；同时通过枚举类校验状态流转合法性，杜绝无效状态变更。

- **分布式事务处理**：支付结果与订单状态绑定采用“本地消息表+重试机制”，若暂不引入MQ组件，可简化为“支付回调接口+幂等处理”方案——支付成功后回调接口携带唯一订单号，后端通过订单号做幂等校验，确保“支付成功则订单状态必更新，更新失败则触发3次重试（间隔1秒）”。

- **订单进度实时推送**：商家在后台更新订单进度时，Service层同步调用Netty推送接口，通过用户ID与Netty Channel的绑定关系，将进度消息精准推送至对应前端（桌面端/小程序端）；

- **消息可靠性保障**：推送前将消息内容存入Redis“order:msg:{orderId}”，前端接收消息后返回ACK确认，Netty服务未收到ACK则10秒内重试2次，仍失败则标记为“待推送”，通过定时任务（每5分钟执行一次）补偿推送。

### 2.3 实时消息协同：Netty+Redis实现跨端通信

针对“群订单消息同步”“商家-用户单聊”核心场景，需实现“消息实时推送、已读状态同步、历史消息可追溯”三大能力，基于Netty+Redis构建轻量通信架构：

- **“再来一单”复购优化**：用户触发复购时，通过订单ID快速查询历史订单明细，利用MyBatis-Plus的selectById接口高效获取数据；系统自动关联菜品表（t_dish）筛选已下架菜品并提示，价格变动通过DTO层封装对比逻辑，前端以红色高亮展示“原价→现价”差异，避免用户误解。

**群订单消息同步**：
        发起者同步商家消息时，后端先将消息存入MySQL“t_chat_msg”表，再通过Redis“publish”发布到对应群聊频道（channel为“group:{groupId}”）；

前端（桌面端/小程序端）订阅对应Redis频道，Netty服务监听频道消息，通过ChannelGroup将消息推送给群内所有在线成员，离线成员下次登录时通过“消息拉取接口”获取历史消息（按时间戳分页）。

**已读状态同步**：前端接收消息后调用“消息确认接口”，后端更新消息表“read_status”字段，同时缓存“用户已读时间戳”到Redis，列表加载时通过时间戳过滤已读消息。

- **Netty服务核心配置**：**线程模型**：采用“主从Reactor线程模型”，BossGroup线程组专注处理连接请求，WorkerGroup线程组负责消息读写，WorkerGroup线程数配置为CPU核心数×2，确保高并发处理能力；

- **连接优化**：设置ChannelOption.SO_KEEPALIVE为true保持长连接，同时配置空闲检测机制（60秒无消息则主动关闭连接），适配小程序端WebSocket短连接转长连接的特性；

- **消息协议**：自定义JSON格式消息体，包含“msgType（单聊/群聊/订单同步）、fromId（发送方ID）、toId（接收方ID）、content（消息内容）、timestamp（发送时间）、ack（确认标识）”核心字段，便于前端差异化处理。

- **群订单消息同步机制**：**消息流转**：群聊发起者同步商家消息时，后端先将消息持久化至MySQL聊天表（t_chat_msg），再通过Redis的publish命令发布至对应群聊频道（频道名：group:{groupId}）；

- **前端接收**：前端（桌面端/小程序端）通过WebSocket订阅对应Redis频道，Netty服务监听频道消息后，通过ChannelGroup将消息广播至群内所有在线成员；

- **离线补偿**：离线成员下次登录时，通过“消息拉取接口”按时间戳分页获取历史消息，确保消息不丢失。

- **已读状态同步**：前端接收消息后调用“消息确认接口”，后端更新t_chat_msg表的read_status字段（0-未读、1-已读），同时将“用户已读时间戳”缓存至Redis“user:read:{userId}:{groupId}”，列表加载时通过时间戳过滤已读消息，优化用户体验。

### 2.4 AI能力集成：后端中间层封装

AI菜品识别（视频/文章内容提取）能力需通过后端统一封装，避免前端直接调用第三方接口带来的密钥泄露、权限不可控等安全风险，核心实现如下：

## 三、前端跨端实现关键技术补充

### 3.1 桌面端（Electron+Vue3+Element UI）：大屏适配与操作优化

- **全功能覆盖**：支持用户端（点单、支付、订单查询、AI食谱上传）与商家端（订单管理、菜单配置、消息回复）全部功能，功能入口布局适配桌面端大屏特性，采用多标签页或侧边栏导航提升操作效率；

- **实时消息接收**：通过Node.js的ws模块与后端Netty服务建立长连接，Electron主进程监听连接状态，连接断开时触发自动重连机制（重连间隔3秒，最大重试次数10次）；消息通过ipcRenderer通信机制同步至渲染进程，确保订单提醒、聊天消息等实时触达；

- **订单管理优化**：采用Element UI的TreeTable组件展示“主订单-子菜品”层级数据，支持批量选中订单进行状态更新；针对≥100条的大量订单数据，启用虚拟滚动（v-infinite-scroll）减少DOM节点渲染，搭配大屏适配的筛选面板提升数据处理效率；

- **本地缓存策略**：利用Electron的localStorage存储用户/商家偏好设置（如默认筛选条件、消息提醒方式），配合electron-store插件存储离线菜单、历史订单等较大体积数据，弱网环境下仍可正常浏览与编辑。

### 3.2 小程序端（UniApp）：移动端轻量化适配

- **全功能对齐**：与桌面端功能完全一致，涵盖用户点单、支付、AI食谱上传及商家核心操作；针对移动端屏幕特性优化界面布局，采用底部Tab导航简化功能入口，关键操作（如订单确认、支付）突出展示；

- **WebSocket适配优化**：基于UniApp的uni.connectSocket API实现WebSocket连接，连接时携带“userId+token”完成后端鉴权，验证通过后建立用户与Netty Channel的绑定关系；小程序退至后台时，通过uni.onAppHide生命周期暂停消息接收，前台唤醒时快速重连并同步未读消息，减少资源占用；

- **页面性能优化**：首页及订单列表采用uni.createIntersectionObserver实现图片懒加载，菜品图片通过阿里云OSS服务压缩（指定宽度300px，质量80%）；表单操作（如菜单编辑、订单备注）支持本地临时存储，避免误操作导致数据丢失；

- **支付流程适配**：调用UniApp的uni.requestPayment API实现支付功能，传入后端生成的统一支付参数（兼容平台币、微信/支付宝支付）；通过uni.onPaymentStateChange监听支付结果，同步触发订单状态更新与消息推送，确保支付链路闭环。

- **AI接口统一封装**：创建AIResourceService服务类，封装百度OCR、阿里云NLP等第三方AI接口，统一请求参数（支持传入视频URL、文章文本）与返回格式（标准化输出菜品名称、核心食材、制作步骤、难度等级、耗时等信息）；同时添加超时重试机制（超时时间5秒，最大重试次数2次，重试间隔1秒），提升接口稳定性；

- **结果缓存与用户修正**：AI提取结果存入Redis“ai:result:{resourceId}”，缓存时长24小时；用户可在前端（桌面端/小程序端）修正提取错误（如补充遗漏食材），修正后同步更新Redis缓存与MySQL用户食谱表（t_user_recipe），并标注“用户修正”标识，区分系统提取与人工优化数据；

- **异步处理优化**：视频内容提取耗时较长（可能超过3秒），采用“异步+回调”模式——前端发起请求后立即返回“taskId”，后端通过Spring Async异步调用AI接口，处理完成后通过Netty将结果推送至对应前端，避免长时间等待导致的超时问题。

## 四、性能与安全优化核心措施

### 4.1 性能优化

- **多级缓存策略**：**热点数据缓存**：菜品信息（t_dish）、商家基础信息（t_merchant）等热点数据用Redis缓存，Key设计为“dish:{dishId}”“merchant:{merchantId}”，缓存有效时长12小时；当菜单信息更新时，主动删除对应Redis缓存，避免缓存脏数据；

- **高频查询缓存**：用户地址列表、历史订单摘要等高频查询数据用Redis List存储，支持按时间戳分页查询，双端请求均能快速响应；

- **缓存一致性保障**：采用“更新数据库+删除缓存”的策略，避免双端因缓存差异导致的功能异常，核心业务数据更新后通过消息通知机制同步双端缓存状态。

**数据库优化**：
        索引设计：订单表建立“userId+createTime”联合索引（查询用户历史订单）、“merchantId+status”联合索引（商家查询待处理订单）；

分库分表：预留订单表分表策略（按“createTime+userId”哈希分表），当单表数据≥100万时启用。

- **数据库性能优化**：**索引设计**：订单表（t_order）建立“userId+createTime”“merchantId+status”“orderNo”等核心索引，双端查询订单时均能实现高效检索；

- **分库分表预留**：预设订单表按“createTime+userId”哈希分表策略，单表数据量≥100万时启用，确保双端海量订单查询性能稳定；

- **读写分离适配**：MySQL配置主从复制，双端读请求（如订单列表查询、菜品浏览）路由至从库，写请求（如订单创建、支付）路由至主库，提升并发处理能力。

**Netty优化**：设置合理的线程池大小（WorkerGroup线程数=CPU核心数×2），消息读写采用“ByteBuf池化”减少内存分配开销，空闲连接检测（60s无消息则关闭连接）。

### 4.2 安全防护

- **多级缓存策略**：**热点数据缓存**：菜品信息（t_dish）、商家基础信息（t_merchant）等热点数据用Redis缓存，Key设计为“dish:{dishId}”“merchant:{merchantId}”，缓存有效时长12小时；当菜单信息更新时，主动删除对应Redis缓存，避免缓存脏数据；

- **高频查询缓存**：用户地址列表、历史订单摘要等高频查询数据用Redis List存储，支持按时间戳分页查询，提升接口响应速度。

- **数据库性能优化**：**索引设计**：订单表（t_order）建立“userId+createTime”联合索引（优化用户历史订单查询）、“merchantId+status”联合索引（优化商家待处理订单筛选），确保查询高效；

- **分库分表预留**：预设订单表分表策略，按“createTime+userId”哈希分表，当单表数据量≥100万时启用，避免单表性能瓶颈。

- **Netty性能调优**：除合理配置线程池大小外，消息读写采用ByteBuf池化技术减少内存分配与回收开销；同时启用TCP_NODELAY参数禁用Nagle算法，降低消息传输延迟。

## 五、开发与部署建议

**部署方案**：
        后端：SpringBoot服务打包为Jar，通过Docker部署，配合Nginx实现负载均衡；Netty服务独立部署，与业务服务分离；

中间件：Redis采用主从架构（1主2从），MySQL主从复制，确保高可用；

**监控与日志**：采用SpringBoot自带监控组件Actuator实现基础监控，日志通过SLF4J+默认日志框架（Logback）输出，兼顾轻量化与问题排查需求；后续业务增长后可平滑扩展至专业监控与日志系统。

#### 5.3.1 SpringBoot自带监控（Actuator）配置

- **接口鉴权与权限控制**：所有前端请求必须携带JWT令牌（Token），令牌包含userId、role（角色标识）等核心信息；后端通过拦截器验证Token有效性，无效或过期则返回401 Unauthorized响应；商家专属接口额外校验请求中的merchantId与Token中的商家ID一致性，杜绝越权访问；

- **敏感数据加密**：用户支付信息、身份证号等敏感数据，MySQL存储时采用AES加密算法加密，密钥通过Spring Cloud Config配置中心统一管理，避免硬编码泄露；前端密码传输采用RSA非对称加密，后端解密后存储BCrypt哈希值，确保密码传输与存储安全；

- **防刷与幂等防护**：支付、短信发送等核心接口通过Redis实现限流（例：1分钟内同一用户最多请求3次），超出阈值返回429 Too Many Requests响应；订单创建、支付回调等接口通过“请求唯一ID”做幂等校验，避免重复请求导致的业务异常。

## 六、补充技术需求点

- **开发规范统一**：**后端规范**：采用Spring Boot Starter统一依赖版本，避免版本冲突；MyBatis-Plus配置分页插件、逻辑删除插件，通过代码生成器生成Entity、DAO、Service基础代码，提升开发效率；接口返回格式统一为“code+message+data”结构，便于前端处理；

- **前端规范**：Vue3项目采用Composition API组织代码逻辑，提升可维护性；UniApp项目统一使用uView UI组件库，确保界面风格一致；所有前端代码提交前通过ESLint校验，杜绝语法错误与代码不规范问题。

- **轻量化部署方案**：**后端部署**：SpringBoot业务服务打包为Jar包，通过Docker容器化部署，搭配Nginx反向代理实现负载均衡与请求分发；Netty服务独立部署，与业务服务分离，便于单独扩容与维护；

- **中间件部署**：Redis采用“1主2从”架构，主节点负责读写，从节点负责备份与读请求分流；MySQL配置主从复制，主库负责写操作，从库负责读操作，提升系统高可用性；

- **监控与日志**：采用SpringBoot自带的Actuator组件实现基础监控，日志通过SLF4J+Logback框架输出，兼顾轻量化与问题排查需求；后续业务增长后可平滑扩展至Prometheus+Grafana监控、ELK日志系统。

- **核心依赖配置**：在pom.xml（Maven）或build.gradle（Gradle）中引入spring-boot-starter-actuator依赖，无需部署独立监控服务，与业务服务一体化运行，降低部署成本；

- **监控端点暴露**：在application.yml配置文件中开启核心监控端点，示例配置：`management: endpoints: web: exposure: include: health,info,metrics,httptrace`——其中health暴露服务健康状态，info暴露应用基础信息，metrics暴露性能指标，httptrace暴露HTTP请求轨迹；

- **核心监控能力**：通过/actuator/metrics接口可查询订单接口响应时间、JVM内存占用、Redis连接数等核心指标；通过/actuator/httptrace接口可追溯异常请求的参数、响应与耗时，快速定位接口问题；

- **监控安全加固**：结合Spring Security对监控端点做权限控制，配置`management.endpoint.health.roles=ADMIN`，限制仅管理员角色可访问，避免监控信息泄露。

- **分布式锁实现**：商家批量更新菜单、订单状态并发变更等场景，采用Redis Redlock分布式锁方案，锁Key设计为“lock:menu:update:{merchantId}”“lock:order:status:{orderId}”，设置合理超时时间（菜单更新锁5秒，订单状态锁3秒），避免并发修改冲突；

- **定时任务配置**：基于Spring Scheduler定时任务组件实现核心业务定时逻辑，例：“未支付订单15分钟自动关闭”“订单完成后48小时提醒商家回复评价”“每日凌晨清理过期Redis缓存”等，定时任务表达式配置在配置文件中，便于动态调整；

- **全局异常处理**：通过@RestControllerAdvice注解实现全局异常处理器，统一捕获Controller、Service层抛出的异常，区分“业务异常”（如菜品缺货、余额不足）与“系统异常”（如数据库连接失败）——业务异常返回明确错误提示，系统异常返回通用提示并记录ERROR级日志，便于问题排查与用户体验优化。
> （注：文档部分内容可能由 AI 生成）